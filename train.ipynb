{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b4e91a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install -q git+https://github.com/openai/CLIP.git\n",
    "# %pip install -q timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d5519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from utils import (\n",
    "    collate_fn,\n",
    "    Transform, \n",
    "    ImageTextDataset, \n",
    "    CLIP_CHECKPOINT, \n",
    "    DATA_ROOT, \n",
    "    AvgMeter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3270edfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e6cdef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer) -> AvgMeter:\n",
    "    loss_meter = AvgMeter()\n",
    "    pbar = tqdm(loader, total=len(loader))\n",
    "    for batch in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        output = model(**batch, return_loss=True)\n",
    "        \n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_meter.update(loss.item(), batch['pixel_values'].size(0))\n",
    "        \n",
    "        pbar.set_postfix(train_loss=loss_meter.avg)\n",
    "    return loss_meter\n",
    "    \n",
    "def eval_epoch(model, loader) -> AvgMeter:\n",
    "    loss_meter = AvgMeter()\n",
    "    pbar = tqdm(loader, total=len(loader))\n",
    "    for batch in pbar:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        output = model(**batch, return_loss=True)\n",
    "        loss = output.loss\n",
    "        loss_meter.update(loss.item(), batch['pixel_values'].size(0))\n",
    "        pbar.set_postfix(eval_loss=loss_meter.avg)\n",
    "    return loss_meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44b192fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071112470c6745ffa4e44b485bd6079d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ebde3982d44ea9925a007cf9d36b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -1; LR 2e-06; LOSS train: 0.9393, eval: 0.7486.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462a0e1accec4129b0ed04a70ea16491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32cfa1fb64494ebb8565bea890856bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0; LR 2e-06; LOSS train: 0.6291, eval: 0.4101.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27775a6bcc949f2a8950696f5efa675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f4524fdaf24ea09675ea51e3ee2542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1; LR 2e-06; LOSS train: 0.5267, eval: 0.3895.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0067bb9419342bdaccf7edda68cfc6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e397b9af7bc4693bfcf5b686baee48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2; LR 2e-06; LOSS train: 0.4740, eval: 0.3884.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4272149851e848cb904106bb0561486c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f032fcd8004864802d755f92a9c05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3; LR 2e-06; LOSS train: 0.4236, eval: 0.3829.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57ca9e32b20408db732a84a6e121430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1700340eb741258d7ccd715b0a4a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4; LR 2e-06; LOSS train: 0.3969, eval: 0.3976.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbda4b705d514d5a853500d6b2629213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394f91e8ccd1434f82f3616df85b8ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5; LR 2e-06; LOSS train: 0.3717, eval: 0.3951.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5f2ad5efc049e881e8602c85f20a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b17f54fff9497bbe537954dacf71f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6; LR 2e-06; LOSS train: 0.3474, eval: 0.4219.\n"
     ]
    }
   ],
   "source": [
    "model = CLIPModel.from_pretrained(CLIP_CHECKPOINT).to(device)\n",
    "\n",
    "batch_size=32\n",
    "train_loader = DataLoader(\n",
    "    ImageTextDataset(DATA_ROOT, \"train\", transform=Transform(224, True)),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    ImageTextDataset(DATA_ROOT, \"eval\", transform=Transform(224, False)),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "lr = 2e-6\n",
    "num_epochs = 7\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=0.1)\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", patience=2, factor=0.5)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_loss = eval_epoch(model, train_loader)\n",
    "    eval_loss = eval_epoch(model, eval_loader)\n",
    "    print(f'EPOCH -1; LR {lr}; LOSS train: {train_loss}, eval: {eval_loss}.')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    cur_lr = optimizer.param_groups[0]['lr']\n",
    "    model.train()\n",
    "    train_loss = train_epoch(model, train_loader, optimizer)\n",
    "    \n",
    "    model.save_pretrained(f'./out/lr{lr}w-1_b{batch_size}x{epoch}/')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        eval_loss = eval_epoch(model, eval_loader)\n",
    "        print(f'EPOCH {epoch}; LR {cur_lr}; LOSS train: {train_loss}, eval: {eval_loss}.')\n",
    "        lr_scheduler.step(eval_loss.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a243c488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
