{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4253c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from utils import Transform, ImageTextDataset, collate_fn, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4259dfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c18f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained('./out/m1/')\n",
    "\n",
    "def text_features(captions) -> np.ndarray:\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(captions, max_length=32, padding=\"max_length\", return_tensors=\"pt\", truncation=True)\n",
    "        features = model.get_text_features(**inputs)\n",
    "\n",
    "    return features.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95b9f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2da2404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9962e-01, 3.7815e-04]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b525f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24857, 512)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precomputed_image_embed = np.load('b32w2x3_25k_features.npy')\n",
    "precomputed_image_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5016c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('meta/valid.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab5ec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13214  4722 14901 ...  7521 10265   250]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "inputs = text_features([\"A photo of a train leaving the train station\"])\n",
    "for text_embed in inputs:\n",
    "    sim = (text_embed @ precomputed_image_embed.T)\n",
    "    order = (-sim).argsort() # order = order.argsort(descending=True)\n",
    "    \n",
    "    for pid in df.iloc[order[:5], 0]:\n",
    "        display(Image(url=f'https://unsplash.com/photos/{pid}/download?force=true&w=360'))\n",
    "        display(HTML(f'<a href=https://unsplash.com/photos/{pid}> source </a>'))\n",
    "    # display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c478145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
